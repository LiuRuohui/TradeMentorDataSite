MODEL_NAME="gpt-4o"
MODEL_TYPE="OpenAI" # if use the gpt series (OpenAI), lamma series (LLAMA)
OPENAI_API_KEY="sk-SI4n4tCu5JmXxqNz6155F63619D44c1d93340c85776c54Fe"
OPENAI_ORGANIZATION=""
API_BASE_URL="http://127.0.0.1:8079" # turn it on if using a VPN
OPENAI_BASE_URL="https://burn.hair/v1"
# BING_SUBSCRIPTION_KEY=""
# BING_SEARCH_URL="https://api.bing.microsoft.com/v7.0/search"
# WOLFRAMALPHA_APP_ID=""

# LLAMA in local server
# open llama3 at local server
# curl -fsSL https://ollama.com/install.sh | sh
# ollama run llama3
# export NO_PROXY=localhost,127.0.0.1 
# MODEL_NAME="llama3"
# MODEL_TYPE="OLLAMA"
# EMBED_MODEL_TYPE="OLLAMA"
# EMBED_MODEL_NAME="nomic-embed-text"
# MODEL_SERVER="http://localhost:11434" # only for local model



